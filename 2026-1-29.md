# Daily Log

**Date:** 29 January 2026

---

## ملخص اللي ذاكرته


- Chapter 5 Replication
  - Leaders and Followers
      - Setting Up New Followers
      - Handling Node Outages
      - Implementation of Replication Logs

        
---

## تلخيصي للي ذاكرته + شرحي

## Setting Up New Followers

زي ما عرفنا ايه الـ Replication، دلوقتي لو حبينا نزود Follower جديد أو Replica، نسأل نفسنا: نعمل ايه عشان يكون عنده داتا مظبوطة؟

لو بس عملنا copy للفايلات من Leader، الموضوع مش هيمشي لأن الداتا عند الـ Leader شغالة طول الوقت. جزء هيتنسخ مظبوط وجزء لا، وده هيخلي الداتا **Inconsistent**.

طيب نقفل الداتا وقت النقل؟

* ممكن، بس ده معناه **Down Time**
* وده غالبًا مش مقبول في أنظمة عالية التوافر.

---

## الحل من غير Down Time

الفكرة: ناخد **snapshot** للداتا ونعرف منين نكمل الـ writes.

الخطوات:

1. ناخد snapshot من داتا الـ Leader في لحظة معينة.
2. ننقل الـ snapshot للـ Follower الجديد.
3. نسأل: إيه اللي اتكتب على الـ Leader بعد ما أخدنا الـ snapshot؟

عشان كده:

* الـ snapshot لازم يكون مربوط **بـ position معين في الـ log**
* الاسم بيختلف حسب نوع الداتا بيز:

  * PostgreSQL → LSN (Log Sequence Number)
  * MySQL → Binlog Coordinates

الفولور يكلم الـ Leader ويقول:

> "ابعتلي كل التغييرات من بعد الـ position ده"

* الفولور يطبق كل الـ changes اللي فاتته.
* أول ما يخلص backlog، نقول عليه **Caught up**.
* بعد كده يبدأ يستقبل writes live زي باقي الـ followers.


## Handling Node Outages

أي Node في السيستم ممكن يقع، يا إما فجأة بسبب crash أو network، يا إما عن قصد عشان maintenance. الهدف هنا إن السيستم كله يفضل شغال، ونقدر نوقع أو نرجّع أي node لوحدها من غير ما نعمل downtime.

الفكرة الأساسية إننا نقلل تأثير سقوط أي node على باقي السيستم.

---

## High Availability مع Leader-Based Replication

في replication المعتمد على Leader، المشاكل بتيجي في حالتين:
يا إما follower يقع، يا إما leader يقع، وكل واحدة ليها تعامل مختلف.

---

## Follower Failure (Catch-up Recovery)

لو follower وقع أو الشبكة فصلت شوية، الموضوع بيبقى بسيط نسبيًا.
كل follower عنده log محلي بيسجل آخر writes وصلته من الـ leader.

لما الفولور يرجع:

* يعرف آخر transaction اشتغل عليها
* يكلم الـ leader
* يطلب كل التغييرات اللي حصلت بعد النقطة دي
* يطبّقها
  وبكده يبقى caught up ويرجع يشتغل عادي.

الحالة دي غالبًا مفيهاش data loss ولا وجع دماغ كبير.

---

## Leader Failure (Failover)

دي الحالة الصعبة. لما الـ leader يقع:

* لازم نختار leader جديد
* نغير اتجاه الـ clients
* نخلي باقي الـ followers يتبعوا الـ leader الجديد

العملية دي اسمها Failover، وممكن تحصل manual أو automatic.

---

## Automatic Failover

أول خطوة إن السيستم يقرر إن الـ leader مات. مفيش طريقة مؤكدة 100%، فغالبًا بيعتمدوا على timeout. لو الـ leader مردش فترة معينة، نفترض إنه وقع.

بعد كده بنختار leader جديد، يا إما عن طريق election بين الـ replicas، يا إما عن طريق node مسؤولة. أحسن اختيار دايمًا هو أكتر follower محدث.

آخر خطوة إننا نعيد تهيئة السيستم:

* الـ clients تبعت writes للـ leader الجديد
* والـ leader القديم لو رجع لازم يتعامل كـ follower

---

## مشاكل Failover

Failover مليان مشاكل حقيقية:

لو replication asynchronous، ممكن الـ leader الجديد ما يكونش استلم كل writes قبل ما القديم يقع. غالبًا الحل إن الـ writes دي تترمي، وده ممكن يكسر توقعات الـ durability عند العميل.

الموضوع يبقى أخطر لما الداتا متربطة بأنظمة تانية. مثال مشهور حصل في GitHub، لما follower قديم اتعيّن leader وبدأ يعيد استخدام IDs كانت اتاخدت قبل كده، فحصل inconsistency وتسريب داتا.

كمان في سيناريوهات معينة ممكن يحصل split brain، يعني nodeين فاكرين نفسهم leaders في نفس الوقت، وده خطر جدًا لأنه ممكن يبوظ الداتا.

غير كده، اختيار timeout نفسه مشكلة: لو طويل recovery يبقى بطيء، ولو قصير ممكن يحصل failover بدون سبب حقيقي.

عشان كده، في فرق كتير بتفضل تعمل failover يدوي حتى لو auto failover متاح.

---

## Implementation of Replication Logs

الـ replication بيعتمد أساسًا على فكرة الـ log، بس شكل الـ log ده بيختلف، وده اللي بيحدد طريقة replication.

---

## Statement-Based Replication

الـ leader بيبعت نفس SQL statements للـ followers، وكل follower ينفذها عنده.

الطريقة دي شكلها بسيط، بس بتقع في مشاكل كتير، خصوصًا مع:

* دوال nondeterministic زي NOW أو RAND
* auto increment
* triggers و stored procedures

عشان كده بقت قليلة الاستخدام، رغم إنها compact.

---

## Write-Ahead Log (WAL) Shipping

هنا الـ leader بيبعت الـ WAL نفسه، اللي هو log منخفض المستوى فيه تغييرات bytes على الديسك.

الميزة إن replication بيبقى دقيق وسريع، لكن العيب الكبير إن الطريقة دي مربوطة جدًا بالـ storage engine والـ database version، فصعب تعمل upgrade من غير downtime.

---

## Logical (Row-Based) Replication

الطريقة دي بتفصل بين storage log و replication log.
الـ log هنا بيبقى منطقي، على مستوى rows، يعني insert و update و delete على الصفوف نفسها.

الميزة إنها:

* مش مربوطة بالـ storage engine
* تسمح باختلاف versions
* أسهل في التكامل مع أنظمة تانية

وده الأساس لفكرة Change Data Capture.

---

## Trigger-Based Replication

في الحالات اللي محتاجة مرونة أعلى، بنطلع replication لطبقة التطبيق باستخدام triggers.

أي تغيير يحصل:

* trigger يشتغل
* يسجل التغيير
* process خارجي يقرأه ويبعته لنظام تاني

الطريقة دي مرنة، بس overhead عالي ومليانة edge cases، فبتستخدم في حالات خاصة بس.

---

## الخلاصة

Replication مش مجرد نسخ داتا.
هو مجموعة trade-offs بين:

* consistency
* availability
* durability
* وسهولة التشغيل والصيانة

والمشاكل اللي بنشوفها هنا مش bugs، دي مشاكل أساسية في أي distributed system.
