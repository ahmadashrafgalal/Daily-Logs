# Daily Log

**Date:** 16 February 2026

---

## ملخص اللي ذاكرته

- Chapter 11 Stream Processing
  - Processing Streams
    - Uses of Stream Processing
    - Reasoning About Time
    - Stream Joins
    - Fault Tolerance

---

## تلخيصي للي ذاكرته + شرحي

إحنا قبل كده عرفنا إن الـ streams بتيجي من كذا حته زي كدا :
user activity events
sensors
database writes (CDC)
message brokers زي Kafka
طيب بعد ما الـ stream توصلك تعمل بيها إيه؟
1) تكتبها في Storage System
يعني مثلا تاخد ال events ة تحطها ف Database او Cache 
زي اكنك بتعمل Sync بين Systems 
طيب ناخد مثال يوضح
عندك في Service بتكتب events في Kafka 
و في Service تاني بتقرا منها و تعمل update 

2) تبعتها لل users  علطول 
زي مثلا Email Alert او Notification هنا الشخص نفسه هو ال Counsumer

3) تبروسيس ال Stream و تنتج stream تاني  
دي مهمه جدا
معناها ف الفلو ده 
Input Stream → Processing Job → Output Stream
Unix pipes
MapReduce

Uses of Stream Processing
1) Complex Event Processing (CEP)
زي ما regex بيدور على pattern في stringال  CEP بيدور على pattern في events
الـ engine:
بيحتفظ بـ state machine داخليًا ولما pattern يتحقق → يطلع complex event
ناخد مثال علي ترتيب
Login failed 3 مرات ,بعدها تغيير password, بعدها تحويل فلوس
دي sequence pattern

الفرق بينها و بين ال Database 
Database:   Data is stored, Query comes and goes
CEP:        Query is stored, Data flows past it

2) Stream Analytics
دي مش مهتمة بـ sequence اوي لكن مهتمة بـ aggregations
زي:
events per second
rolling average
percentiles
trend detection

وهنا يظهر مفهوم ال Window
عشان stream infinite
لازم تقول:
أنا هحسب على آخر 5 دقائق بس
دي اسمها window.

3)  Maintaining Materialized Views
دي يعني انك تبني  من Stream Events حاجات زي 
Search index
Cache
Aggregated table
Read model في CQRS

4) Search on Streams
وده شبه CEP شوية  بدل ما تخزن documents وتعمل query عليهم
هنا تخزن queries والdocuments هي اللي تمشي قدامهم
زي:
real estate alerts
media monitoring

5) RPC & Message passing 
اولا كدا الMessage Passing
زي:
Actor model
Akka
Erlang
دي systems بتبعت messages لبعض لكن الكتاب بيقول مش بنعتبرها Stream Processing غالبًا
ليه؟
| Actor Systems             | Stream Processing       |
| ------------------------- | ----------------------- |
| هدفها concurrency         | هدفها data management   |
| غالبًا ephemeral messages | غالبًا durable logs     |
| One-to-one                | Multi-subscriber        |
| ممكن cycles               | غالبًا acyclic pipeline |

طيب فين RPC هنا؟
RPC = Remote Procedure Call
يعني Service A بينادي function في Service B
زي:
user = user_service.get_user(id)
شكله local call بس هو network call.

الفرق بين RPC و Stream Processing
RPC:
Request/Response
synchronous غالبًا
client مستني الرد
one-to-one
ephemeral


Stream:
async
fire-and-forget
durable
multi-consumer
pipeline based

ليه اتذكرت RPC هنا؟

عشان يقول ان مش أي system فيه messages يبقى stream processing
Actor frameworks ممكن تعمل بيها stream processing لكن مش معمولة أساسًا عشان كده وغالبًا مش fault tolerant قوي



Reasoning About Time
في مشكله حقيقيه ف ال Stream وهي الوقت, طب ليه؟
لو سمعت Average Over last 5 min هتحسها واضحه عادي بس في مشكله 
هي اخر 5 دقايق بالنسبه لمين؟ وقت الevent ولا وقت المعالجه ولا وقت ايه؟
كتير من frameworks بيستخدموا Processing Time
يعني:
وقت المعالجة على السيرفر
وده سهل جدًا في التنفيذ لكن فيه مشكلة خطيرة

Event Time vs Processing Time
Event Time
هو الوقت اللي الحدث حصل فيه فعلًا
مثلا يوزر ضغط زرار الساعة 10:03:15

Processing Time
هو الوقت اللي السيرفر عالج فيه الحدث ممكن يبقى
10:03:16 أو 10:05 أو بعد ساعتين



Stream Joins

في batch عندك dataset كامل تقدر تعمل sort تقدر تبني hash table كله finite 

لكن في stream البيانات مش بتخلص فـ join هنا أصعب بكتير

متقسمين لـ 3 أنواع:
Stream–Stream Join
Stream–Table Join
Table–Table Join

1) Stream–Stream Join (Window Join)
في مثال ال Search + Click
عندك:
Stream 1: search events
Stream 2: click events
عايز تحسب:
click-through rate
المفتاح المشترك:
session_id
المشكلة هي ان اليوزر ممكن ميدوسش خالص او ممكن يدوس بعد ثواني أو بعد أسبوع
و الclick ممكن يوصل قبل search بسبب network
يبقى مش هينفع join بسيط

الحل Window Join
تقول مثلًا هنربط search بـ click لو الفرق بينهم ≤ ساعة
يبقى لازم تحتفظ بكل search events في آخر ساعة
و تحتفظ بكل click events في آخر ساعة
Indexed by session_id

كل ما event ييجي:
يتحط في state ندور في الـ state التانية
لو match → emit event
لو search انتهت window من غير click → emit “no click”

2) Stream–Table Join (Stream Enrichment) 
دي من أكتر الحاجات اللي بتشوفها في systems الحقيقية مثلا
Stream:
user activity events
Table:
user profiles
عايز enrich كل activity بمعلومات اليوزر

التنفيذ العادي 
كل event اعمل  RPC علي database و جيب البروفايل و رجعه
طبعا هيبقي في laetncy و tigh coupling و مش scalable 

الحل الصح:
Load table locally inside stream processor
زي in-memory hash table او local index 
لكن في مشكله ان الداتا بتتغير  كل شويه
ف ال batch كنت باخد ال snapshot ثابت من ال table 
يبقي هنا لازم  نقرأ changelog بتاع الtable كـ stream
Stream A: activity events
Stream B: profile updates (CDC)
والـ processor يحدث نسخة profile local
enrich events بناءً على أحدث state


3) Table–Table Join (Materialized View Maintenance)
مثلا Twitter Timeline
لو عندك:
Table 1: tweets
Table 2: follows
الـ query:
```sql
SELECT follows.follower_id AS timeline_id,
array_agg(tweets.* ORDER BY tweets.timestamp DESC)
FROM tweets
JOIN follows ON follows.followee_id = tweets.sender_id
GROUP BY follows.follower_id
```
لو عملتها real-time query كل مرة هتموت السيرفر 
الحل Materialized View
يعني:
لما user يبعث tweet يتحط في timeline كل followers
لما user يعمل follow نحط له tweets القديمة
لما يعمل unfollow نشيل tweets
ده كله processing events.

