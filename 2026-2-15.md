# Daily Log

**Date:** 15 February 2026

---

## ملخص اللي ذاكرته

- Chapter 11 Stream Processing
  - Databases and Streams
    - Keeping Systems in Sync
    - Change Data Capture
    - Event Sourcing
    - State, Streams, and Immutability

---

## تلخيصي للي ذاكرته + شرحي

مش بس الداتا اللي جايه من برا بتبقي Stream لا
ال Database نفسها ممكن تتشاف على إنها Stream of Events

يعني إيه؟
أي write بتحصل على الـ database (insert / update / delete) دي في الحقيقة Event حصل في وقت معين.
فبدل ما نبص للداتابيز على إنها بس جداول مخزنة على disk،
نبص لها على إنها Log من الأحداث اللي حصلت بترتيب معين وده نفس تفكير الـ message brokers زي Kafka.


Replication Log = Event Stream
لما بيكون عندك Leaderو Followers
الـ Leader بيكتب transaction وفي نفس الوقت بيكتبها في replication log الـ followers بياخدوا الـ log ده ويمشوا وراه بالترتيب.
وده نفس مبدأ:
State Machine Replication
اللي بيقول لو كل replica استقبل نفس الأحداث وبنفس الترتيب والـ processing deterministic
 كلهم هيطلعوا بنفس النتيجة يعني replication = stream processing

 المشكلة بقى: Keeping Systems in Sync
في الحقيقة مفيش system واحد بيعمل كل حاجة في application حقيقي بيبقى عندك
OLTP database
Cache (زي Redis)
Search index (زي Elasticsearch)
Data warehouse
كل واحدة ليها نسخة من نفس الداتا بس بتمثيل مختلف optimized لغرضها.
إزاي نخليهم synchronized؟
خلي Database هي المصدر الوحيد للحقيقة (Source of Truth)
واطلع منها Stream (log of changes)
وخلي:
search index
cache
data warehouse
يبقوا followers للـ database log
يعني زي replication بس cross-systems replication.


Change Data Capture CDC

المشكلة زمان إن Replication log بتاع الداتابيز كان internal detail
يعني مش public API مش معمول عشان تقرأه
فالناس كانت بتتعامل مع الداتابيز من خلال SQL,Queries,ORM لكن مش من خلال الـ log

CDC بيقول
راقب كل تغيير بيحصل في الداتابيز واطلعه كـ stream وابعته لباقي السيستمز

يعني بدل dual writes نخلي
Database = Leader
Search index / Cache / Warehouse = Followers
وكلهم يسمعوا change stream.


في طريقتين عشان ننفذ ال CDC
1) Triggers
اننا نعمل triggger علي كل table بيتم بعد ال Insert او Update
ويكتب في changelog table بس طبعا هيأثر علي ال Performance

2) Parsing Replication Log
الاقوي انك تقرا ال Replication Log
في حاجات زيWAL / binlog / oplog بس يعني ايه؟
كل Database محترمة بتعمل حاجة اسمها Write-Ahead Log (WAL)
في PostgreSQL اسمه WAL
في MySQL اسمه binlog
في MongoDB اسمه oplog

الفكرة واحدة قبل ما الداتابيز تكتب الداتا في الجدول بتكتبها الأول في log sequential على الديسك.
ليه؟
عشان crash recovery
عشان replication
عشان الترتيب يبقى محفوظ
يعني لو عملت:
```sql
UPDATE users SET name = "Ahmed" WHERE id = 5;
```
اللي بيحصل تحت الكواليس:
يتكتب record في WAL
بعد كده يتطبق على الجدول
فالـ WAL ده فيه:
كل التغييرات اللي حصلت على الداتابيز
وبالترتيب الصح 100%

هنا ييجي دور Debezium
ده Tool شغلته الوحيدة يقعد يراقب WAL / binlog ويحول كل change لـ Event ويبعتها لـ Kafka يعني هو مش بيقرأ من الجداول هو بيقرأ من الـ replication log نفسه وده قوي جدًا لأنه مش محتاج triggers مش بيأثر على performance زي SQL-level hooks بيضمن نفس ترتيب الكتابة


